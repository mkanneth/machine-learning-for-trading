{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "from talib import RSI, BBANDS, MACD\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "import pywt\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "from alphalens.performance import *\n",
    "from alphalens.plotting import *\n",
    "from alphalens.tears import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/assets.h5'\n",
    "START = 2000\n",
    "END = 2018\n",
    "idx = pd.IndexSlice\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = (store['quandl/wiki/prices']\n",
    "              .loc[idx[str(START):str(END), :], 'adj_close']\n",
    "              .unstack('ticker'))\n",
    "    stocks = store['us_equities/stocks'].loc[:, ['marketcap', 'ipoyear', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_historical_returns(input_df,data_frequency=\"D\",return_intervals=[1,4]):\n",
    "    #input_df: Dataframe with daily/weekly/monthly stock price data\n",
    "    #return_invervals should be in specified in the increment the input_df is\n",
    "    #returns are normalized to the data_frequence (i.e. daily data is normalized to daily returns, monthly to per month, etc)\n",
    "\n",
    "    df = input_df.copy()\n",
    "    columns = df.columns\n",
    "    returns = pd.DataFrame()\n",
    "\n",
    "    for i in return_intervals:\n",
    "        for col in columns:\n",
    "            returns[f'{col}_{i}{data_frequency}_return'] = df[col].pct_change(i).add(1).pow(1/i).sub(1)\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this function to work, x_df and y_df need to have datetime indexes with the same dates to join on\n",
    "def rolling_OLS(x_df,y_df,rolling_window):\n",
    "\n",
    "    if isinstance(x_df.index,pd.DatetimeIndex):\n",
    "        pass\n",
    "    else:\n",
    "        x_df.index = x_df.index.to_timestamp()\n",
    "\n",
    "    if isinstance(y_df.index,pd.DatetimeIndex):\n",
    "        pass\n",
    "    else:\n",
    "        y_df.index = y_df.index.to_timestamp()\n",
    "   \n",
    "    \n",
    "    y_df.index.name = 'date'\n",
    "    x_df.index.name = 'date'\n",
    "\n",
    "    y_name = y_df.columns[0]\n",
    "    regression_df = x_df.join(y_df).sort_index()\n",
    "\n",
    "\n",
    "    regression = RollingOLS(endog=regression_df[y_name],\n",
    "                            exog=sm.add_constant(regression_df.drop(y_name,axis=1)),\n",
    "                            window=min(rolling_window,len(regression_df)-1)\n",
    "                            ).fit(params_only=True)\n",
    "    \n",
    "    params = regression.params.drop('const',axis=1)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to pull Fama French Data\n",
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3', 'famafrench', start='2000')[0].drop('RF', axis=1)\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "factor_data = factor_data.div(100).resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBands doesn't handle N/A well, need to drop them or fill in na witha average of edges\n",
    "up, mid, low = BBANDS(prices['AAPL'].dropna(), timeperiod=10, nbdevup=2, nbdevdn=2, matype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative strength index, >=70 means overbought, <=30 means underbought\n",
    "rsi = RSI(prices['AAPL'].dropna(),timeperiod=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACD is simply the difference between the fast EMA and slow EMA\n",
    "#macdsignal is just the moving average of the macd, the time periods is based on the \"signalperiod\" variable\n",
    "#macdhist is just the difference between the macd and the macdsignla\n",
    "\n",
    "macd, macdsignal, macdhist = MACD(prices['AAPL'].dropna(), fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "sns.lineplot(macdsignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling Pandas Functions\n",
    "\n",
    "#Below is an example of what it looks like, rolling provides a window of values to use in another function (mean in this case)\n",
    "#df.rolling(window=...).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kalman Filters\n",
    "\n",
    "\n",
    "kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = 0,   #suggested in book\n",
    "                  initial_state_covariance = 1, #suggested in book\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.01)\n",
    "\n",
    "#prices_df would be daily prices of a stock\n",
    "state_means, _ = kf.filter(prices_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOLDING_PERIODS = (5, 10, 21, 42)\n",
    "QUANTILES = 5\n",
    "\n",
    "#Factor_df can be a df, but needs to have a single factor. Index needs to be multiindex, first \"date\" and then \"asset\". \"date\" need to have a timezone to work\n",
    "#so it will be three \"columns\", total, two of them are the indexes and one is the factor that you are analyzing\n",
    "\n",
    "#prices df needs to be a \"wide\" df, with each asset's prices being a new column. The index needs to be a singel datetime index WITH timezone. \n",
    "factor_df = pd.read_csv('sample_factor_data.csv')\n",
    "\n",
    "#reformatting the columns to be indexes\n",
    "factor_df = factor_df.set_index([pd.to_datetime(factor_df['date']),'asset'])\n",
    "factor_df.drop('date',axis=1,inplace=True)\n",
    "\n",
    "prices = pd.read_csv('stock_prices_daily.csv')\n",
    "prices['Unnamed: 0'] = pd.to_datetime(prices['Unnamed: 0'])\n",
    "prices = prices.set_index(['Unnamed: 0'])\n",
    "\n",
    "alphalens_data = get_clean_factor_and_forward_returns(factor=factor_df,\n",
    "                                                      prices=prices,\n",
    "                                                      periods=HOLDING_PERIODS,\n",
    "                                                      quantiles=QUANTILES)\n",
    "\n",
    "\n",
    "#The below simply plots a potential cumulative returns graphs based on quantiles, you need to specify a single period from your above quantile options twice below\n",
    "mean_return_by_q_daily, std_err = mean_return_by_quantile(alphalens_data, by_date=True)\n",
    "plot_cumulative_returns_by_quantile(mean_return_by_q_daily['5D'], period='5D', freq=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_return_by_q_daily, std_err = mean_return_by_quantile(alphalens_data, by_date=True)\n",
    "plot_cumulative_returns_by_quantile(mean_return_by_q_daily['5D'], period='5D', freq=None)\n",
    "plt.tight_layout()\n",
    "\n",
    "#The resulting plot shows what an ideal factor should have, i.e. quantile 5 does the best and 1 does the worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = factor_information_coefficient(alphalens_data)\n",
    "\n",
    "plot_ic_ts(ic[['5D']])\n",
    "plt.tight_layout()\n",
    "sns.despine();\n",
    "\n",
    "#Below is alternative plot, comment out above to see this one \n",
    "# ic_by_year = ic.resample('A').mean()\n",
    "# ic_by_year.index = ic_by_year.index.year\n",
    "# ic_by_year.plot.bar(figsize=(14, 6))\n",
    "# plt.tight_layout();\n",
    "\n",
    "#The above plots the information cooeficient but takes the inital alphalens data as the input so can only be for one factor at a time\n",
    "#NOTE: This is NOT the IR (Information Ratio), just a proxy metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
